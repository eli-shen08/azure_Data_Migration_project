{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Define paths\n",
        "silver_base_path = \"abfss://migration@hierarchstorage25.dfs.core.windows.net/silver/migration/\"\n",
        "output_base_path = \"abfss://migration@hierarchstorage25.dfs.core.windows.net/gold/migration/\"\n",
        "\n",
        "# Enable Delta Lake optimizations\n",
        "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n",
        "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
        "\n",
        "def create_dimension_tables():\n",
        "    \"\"\"Create dimension tables following proper gold layer standards.\"\"\"\n",
        "    logger.info(\"Creating dimension tables for Gold layer\")\n",
        "    \n",
        "    # Load data from the silver layer\n",
        "    customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "    accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "    loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "    \n",
        "    # Create DIM_CUSTOMERS - Master customer dimension table\n",
        "    dim_customers = customers_df.select(\n",
        "        col(\"CustomerID\").alias(\"customer_key\"),\n",
        "        col(\"CustomerID\").alias(\"customer_id\"),\n",
        "        col(\"FirstName\").alias(\"first_name\"),\n",
        "        col(\"LastName\").alias(\"last_name\"),\n",
        "        col(\"FullName\").alias(\"full_name\"),\n",
        "        col(\"Email\").alias(\"email\"),\n",
        "        col(\"PhoneNumber\").alias(\"phone_number\"),\n",
        "        col(\"Address\").alias(\"address\"),\n",
        "        col(\"City\").alias(\"city\"),\n",
        "        col(\"State\").alias(\"state\"),\n",
        "        col(\"Country\").alias(\"country\"),\n",
        "        col(\"ZipCode\").alias(\"zip_code\"),\n",
        "        col(\"SignupDate\").alias(\"signup_date\"),\n",
        "        col(\"CustomerAge\").alias(\"customer_age\"),\n",
        "        col(\"CustomerSegment\").alias(\"customer_segment\"),\n",
        "        col(\"CustomerTier\").alias(\"customer_tier\"),\n",
        "        current_timestamp().alias(\"etl_timestamp\"),\n",
        "        lit(\"ACTIVE\").alias(\"record_status\")\n",
        "    ).distinct()\n",
        "    \n",
        "    # Create DIM_ACCOUNTS - Master account dimension table\n",
        "    dim_accounts = accounts_df.select(\n",
        "        col(\"AccountID\").alias(\"account_key\"),\n",
        "        col(\"AccountID\").alias(\"account_id\"),\n",
        "        col(\"CustomerID\").alias(\"customer_id\"),\n",
        "        col(\"AccountType\").alias(\"account_type\"),\n",
        "        col(\"Balance\").alias(\"current_balance\"),\n",
        "        col(\"OpenDate\").alias(\"open_date\"),\n",
        "        col(\"AccountAgeYears\").alias(\"account_age_years\"),\n",
        "        col(\"AccountStatus\").alias(\"account_status\"),\n",
        "        col(\"AccountTier\").alias(\"account_tier\"),\n",
        "        col(\"IsHighValue\").alias(\"is_high_value\"),\n",
        "        current_timestamp().alias(\"etl_timestamp\"),\n",
        "        lit(\"ACTIVE\").alias(\"record_status\")\n",
        "    ).distinct()\n",
        "    \n",
        "    # Create DIM_LOANS - Master loan dimension table\n",
        "    dim_loans = loans_df.select(\n",
        "        col(\"LoanID\").alias(\"loan_key\"),\n",
        "        col(\"LoanID\").alias(\"loan_id\"),\n",
        "        col(\"CustomerID\").alias(\"customer_id\"),\n",
        "        col(\"LoanType\").alias(\"loan_type\"),\n",
        "        col(\"LoanAmount\").alias(\"loan_amount\"),\n",
        "        col(\"InterestRate\").alias(\"interest_rate\"),\n",
        "        col(\"LoanStartDate\").alias(\"loan_start_date\"),\n",
        "        col(\"LoanEndDate\").alias(\"loan_end_date\"),\n",
        "        col(\"LoanDurationYears\").alias(\"loan_duration_years\"),\n",
        "        col(\"TotalInterest\").alias(\"total_interest\"),\n",
        "        col(\"MonthlyPayment\").alias(\"monthly_payment\"),\n",
        "        col(\"LoanStatus\").alias(\"loan_status\"),\n",
        "        col(\"RiskCategory\").alias(\"risk_category\"),\n",
        "        col(\"LoanToValueRatio\").alias(\"loan_to_value_ratio\"),\n",
        "        col(\"IsHighRisk\").alias(\"is_high_risk\"),\n",
        "        current_timestamp().alias(\"etl_timestamp\"),\n",
        "        lit(\"ACTIVE\").alias(\"record_status\")\n",
        "    ).distinct()\n",
        "    \n",
        "    # Write dimension tables\n",
        "    dim_customers.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_customers/\")\n",
        "    dim_accounts.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_accounts/\")\n",
        "    dim_loans.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_loans/\")\n",
        "    \n",
        "    logger.info(\"Dimension tables created successfully\")\n",
        "    return dim_customers, dim_accounts, dim_loans\n",
        "\n",
        "def create_fact_tables():\n",
        "    \"\"\"Create fact tables following proper gold layer standards.\"\"\"\n",
        "    logger.info(\"Creating fact tables for Gold layer\")\n",
        "    \n",
        "    # Load data from silver layer\n",
        "    customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "    accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "    loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "    transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "    payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "    \n",
        "    # Create FACT_TRANSACTIONS - Transaction fact table with proper grain\n",
        "    fact_transactions = transactions_df.join(\n",
        "        accounts_df.select(\"AccountID\", \"CustomerID\"), \"AccountID\"\n",
        "    ).select(\n",
        "        col(\"TransactionID\").alias(\"transaction_key\"),\n",
        "        col(\"TransactionID\").alias(\"transaction_id\"),\n",
        "        col(\"AccountID\").alias(\"account_key\"),\n",
        "        col(\"CustomerID\").alias(\"customer_key\"),\n",
        "        col(\"TransactionDate\").alias(\"transaction_date\"),\n",
        "        col(\"Amount\").alias(\"transaction_amount\"),\n",
        "        col(\"TransactionType\").alias(\"transaction_type\"),\n",
        "        col(\"TransactionCategory\").alias(\"transaction_category\"),\n",
        "        col(\"TransactionSize\").alias(\"transaction_size\"),\n",
        "        col(\"Description\").alias(\"transaction_description\"),\n",
        "        col(\"TransactionDayOfWeek\").alias(\"transaction_day_of_week\"),\n",
        "        col(\"TransactionMonth\").alias(\"transaction_month\"),\n",
        "        col(\"TransactionYear\").alias(\"transaction_year\"),\n",
        "        col(\"IsWeekend\").alias(\"is_weekend_transaction\"),\n",
        "        col(\"IsLargeTransaction\").alias(\"is_large_transaction\"),\n",
        "        current_timestamp().alias(\"etl_timestamp\")\n",
        "    )\n",
        "    \n",
        "    # Create FACT_PAYMENTS - Payment fact table with proper grain\n",
        "    fact_payments = payments_df.join(\n",
        "        loans_df.select(\"LoanID\", \"CustomerID\"), \"LoanID\"\n",
        "    ).select(\n",
        "        col(\"PaymentID\").alias(\"payment_key\"),\n",
        "        col(\"PaymentID\").alias(\"payment_id\"),\n",
        "        col(\"LoanID\").alias(\"loan_key\"),\n",
        "        col(\"CustomerID\").alias(\"customer_key\"),\n",
        "        col(\"PaymentDate\").alias(\"payment_date\"),\n",
        "        col(\"PaymentAmount\").alias(\"payment_amount\"),\n",
        "        col(\"PaymentMethod\").alias(\"payment_method\"),\n",
        "        col(\"PaymentMethodCategory\").alias(\"payment_method_category\"),\n",
        "        col(\"PaymentSize\").alias(\"payment_size\"),\n",
        "        col(\"DaysSinceLastPayment\").alias(\"days_since_last_payment\"),\n",
        "        col(\"IsLatePayment\").alias(\"is_late_payment\"),\n",
        "        col(\"IsLargePayment\").alias(\"is_large_payment\"),\n",
        "        current_timestamp().alias(\"etl_timestamp\")\n",
        "    )\n",
        "    \n",
        "    # Create FACT_CUSTOMER_ACCOUNTS - Bridge table for customer-account relationships\n",
        "    fact_customer_accounts = accounts_df.select(\n",
        "        col(\"AccountID\").alias(\"account_key\"),\n",
        "        col(\"CustomerID\").alias(\"customer_key\"),\n",
        "        col(\"AccountType\").alias(\"account_type\"),\n",
        "        col(\"Balance\").alias(\"account_balance\"),\n",
        "        col(\"AccountStatus\").alias(\"account_status\"),\n",
        "        col(\"AccountTier\").alias(\"account_tier\"),\n",
        "        col(\"IsHighValue\").alias(\"is_high_value_account\"),\n",
        "        current_timestamp().alias(\"etl_timestamp\")\n",
        "    )\n",
        "    \n",
        "    # Write fact tables\n",
        "    fact_transactions.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_transactions/\")\n",
        "    fact_payments.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_payments/\")\n",
        "    fact_customer_accounts.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_customer_accounts/\")\n",
        "    \n",
        "    logger.info(\"Fact tables created successfully\")\n",
        "    return fact_transactions, fact_payments, fact_customer_accounts\n",
        "\n",
        "def create_aggregated_tables():\n",
        "    \"\"\"Create aggregated tables for analytics and reporting.\"\"\"\n",
        "    logger.info(\"Creating aggregated tables for Gold layer\")\n",
        "    \n",
        "    # Load fact tables\n",
        "    fact_transactions = spark.read.format(\"delta\").load(f\"{output_base_path}fact_transactions/\")\n",
        "    fact_payments = spark.read.format(\"delta\").load(f\"{output_base_path}fact_payments/\")\n",
        "    \n",
        "    # Create AGG_CUSTOMER_SUMMARY - Customer-level aggregations\n",
        "    agg_customer_summary = fact_transactions.groupBy(\"customer_key\") \\\n",
        "        .agg(\n",
        "            count(\"*\").alias(\"total_transactions\"),\n",
        "            sum(\"transaction_amount\").alias(\"total_transaction_amount\"),\n",
        "            avg(\"transaction_amount\").alias(\"avg_transaction_amount\"),\n",
        "            max(\"transaction_amount\").alias(\"max_transaction_amount\"),\n",
        "            min(\"transaction_amount\").alias(\"min_transaction_amount\"),\n",
        "            countDistinct(\"transaction_type\").alias(\"transaction_type_count\"),\n",
        "            sum(when(col(\"is_large_transaction\"), 1).otherwise(0)).alias(\"large_transaction_count\"),\n",
        "            sum(when(col(\"is_weekend_transaction\"), 1).otherwise(0)).alias(\"weekend_transaction_count\")\n",
        "        ) \\\n",
        "        .withColumn(\"etl_timestamp\", current_timestamp())\n",
        "    \n",
        "    # Create AGG_ACCOUNT_SUMMARY - Account-level aggregations\n",
        "    agg_account_summary = fact_transactions.groupBy(\"account_key\") \\\n",
        "        .agg(\n",
        "            count(\"*\").alias(\"total_transactions\"),\n",
        "            sum(\"transaction_amount\").alias(\"total_transaction_amount\"),\n",
        "            avg(\"transaction_amount\").alias(\"avg_transaction_amount\"),\n",
        "            sum(when(col(\"transaction_category\") == \"Income\", col(\"transaction_amount\")).otherwise(0)).alias(\"total_deposits\"),\n",
        "            sum(when(col(\"transaction_category\") == \"Expense\", col(\"transaction_amount\")).otherwise(0)).alias(\"total_withdrawals\"),\n",
        "            count(when(col(\"transaction_category\") == \"Income\", 1)).alias(\"deposit_count\"),\n",
        "            count(when(col(\"transaction_category\") == \"Expense\", 1)).alias(\"withdrawal_count\")\n",
        "        ) \\\n",
        "        .withColumn(\"etl_timestamp\", current_timestamp())\n",
        "    \n",
        "    # Create AGG_LOAN_SUMMARY - Loan-level aggregations\n",
        "    agg_loan_summary = fact_payments.groupBy(\"loan_key\") \\\n",
        "        .agg(\n",
        "            count(\"*\").alias(\"total_payments\"),\n",
        "            sum(\"payment_amount\").alias(\"total_payment_amount\"),\n",
        "            avg(\"payment_amount\").alias(\"avg_payment_amount\"),\n",
        "            max(\"payment_amount\").alias(\"max_payment_amount\"),\n",
        "            min(\"payment_amount\").alias(\"min_payment_amount\"),\n",
        "            countDistinct(\"payment_method\").alias(\"payment_method_count\"),\n",
        "            sum(when(col(\"is_late_payment\"), 1).otherwise(0)).alias(\"late_payment_count\"),\n",
        "            avg(\"days_since_last_payment\").alias(\"avg_days_since_payment\")\n",
        "        ) \\\n",
        "        .withColumn(\"etl_timestamp\", current_timestamp())\n",
        "    \n",
        "    # Write aggregated tables\n",
        "    agg_customer_summary.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}agg_customer_summary/\")\n",
        "    agg_account_summary.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}agg_account_summary/\")\n",
        "    agg_loan_summary.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}agg_loan_summary/\")\n",
        "    \n",
        "    logger.info(\"Aggregated tables created successfully\")\n",
        "    return agg_customer_summary, agg_account_summary, agg_loan_summary\n",
        "\n",
        "# Execute Gold layer creation\n",
        "try:\n",
        "    logger.info(\"Starting Silver to Gold layer processing\")\n",
        "    \n",
        "    # Create dimension tables\n",
        "    dim_customers, dim_accounts, dim_loans = create_dimension_tables()\n",
        "    \n",
        "    # Create fact tables\n",
        "    fact_transactions, fact_payments, fact_customer_accounts = create_fact_tables()\n",
        "    \n",
        "    # Create aggregated tables\n",
        "    agg_customer_summary, agg_account_summary, agg_loan_summary = create_aggregated_tables()\n",
        "    \n",
        "    print(\"Silver To Gold Processing Completed Successfully!\")\n",
        "    logger.info(\"Gold layer created with proper dimensional modeling standards\")\n",
        "    \n",
        "except Exception as e:\n",
        "    logger.error(f\"Error in Silver to Gold processing: {str(e)}\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    raise\n",
        "\n",
        ""
      ]
    }
  ]
}